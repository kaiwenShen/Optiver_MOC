{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T09:35:38.746491Z",
     "start_time": "2023-11-12T09:35:38.320546200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T09:35:38.747493Z",
     "start_time": "2023-11-12T09:35:38.384859Z"
    }
   },
   "outputs": [],
   "source": [
    "# We will import the necessary libraries here. You can import any librariese you need for your beautiful factors!\n",
    "from in_house_validation import utils, factor_design, factor_backtest\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import queue\n",
    "from scipy.stats import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('research_train_set.csv')\n",
    "df_test = pd.read_csv('research_test_set.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:35:50.303936500Z",
     "start_time": "2023-11-12T09:35:38.444595700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "col2index_map = utils.load_json('./in_house_validation/col2index_map.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:35:50.453516500Z",
     "start_time": "2023-11-12T09:35:50.314936100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "df_train_dic_sorted = utils.load_json('./in_house_validation/df_train_dic_sorted.json')\n",
    "df_test_dic_sorted = utils.load_json('./in_house_validation/test_data_dic_sorted.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:39:27.785111600Z",
     "start_time": "2023-11-12T09:35:50.448516300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "existed_factor_train = utils.load_json('./in_house_validation/existed_factors.json')\n",
    "existed_factor_test = utils.load_json('./in_house_validation/existed_factor_test.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:39:53.328625500Z",
     "start_time": "2023-11-12T09:39:27.764462800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "factor_performance_train = utils.load_json('./in_house_validation/factor_performance.json')\n",
    "factor_performance_test = utils.load_json('./in_house_validation/factor_performance_test.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:39:53.337625500Z",
     "start_time": "2023-11-12T09:39:52.996068200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# New factor here"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "def s1_imbalance_signed_pow_opt(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    '''\n",
    "    This will be the main function to design your factors for the competition. Please\n",
    "    define only one factor here each time. We provide you with:\n",
    "\n",
    "    Current_data: a dictionary in the format of {column_name: column_value}, where column_name is from the original\n",
    "    dataframe\n",
    "\n",
    "    hist_list: A list for you to save the previous factor values (optional). For instance,\n",
    "    if you are calculating a 100-day Moving Average (MA), then you can save the first calculated\n",
    "    MA in hist_list, and then for the next MA calculation, you can use the saved ones.\n",
    "    '''\n",
    "    ###################### ADD YOUR CODE HERE FOR FACTORS DESIGN ######################\n",
    "    # convert the current_data to your choice of numpy or pandas dataframe\n",
    "    # current_data = pd.DataFrame(current_data)\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n",
    "          (current_data[:, col2index_map['bid_size']] + current_data[:, col2index_map['ask_size']])\n",
    "    ############################## NAN/Inf handling ######################################\n",
    "    # if you have nan in your factor value, please fill it reasonably\n",
    "    # res = np.nan_to_num(res) # this is slow because it also checks for inf.\n",
    "    # res = np.where(np.isnan(res), 0, res)  # this is slightly faster than np.nan_to_num\n",
    "    res[np.isnan(res)] = 0  # this is the fastest way to fill nan\n",
    "    ############################## END OF YOUR CODE ##############################\n",
    "    return np.sign(-res) * np.abs(\n",
    "        res) ** 1.4242424242424243  # The return value MUSE BE a numpy array, with no NaN value\n",
    "    # reason: s1_imbalance have most information in sign, sign can be think of as sign*abs**0. we optimize the power and get 1.424 as the best\n",
    "    ####################################################################################\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "outputs": [],
   "source": [
    "def past_10s_ret(current_data: dict, hist_list=[]):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if current_time < 10:\n",
    "        if len(hist_list) == 0:\n",
    "            hist_list.append(\n",
    "                queue.Queue())  # if we directly claim hist_list = [queue.Queue()], it will be a local variable\n",
    "        else:\n",
    "            hist_list[0].queue.clear()\n",
    "        hist_list[0].put(current_wap)\n",
    "        res = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[0].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[0].get()\n",
    "        res = (current_wap - past_wap) / past_wap\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return -res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "def past_30s_ret_rank(current_data: dict, hist_list=[]):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if current_time < 30:\n",
    "        if current_time == 0:\n",
    "            if len(hist_list) == 0:\n",
    "                hist_list.append(queue.Queue())\n",
    "            else:\n",
    "                hist_list[0].queue.clear()\n",
    "        hist_list[0].put(current_wap)\n",
    "        res = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[0].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[0].get()\n",
    "        res = (current_wap - past_wap) / past_wap\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return -stats.rankdata(res, method='min') / (len(res) + 1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "def stock_20s_ret_deviate_from_index(current_data: dict, hist_list=[]):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if len(hist_list) == 0:\n",
    "        hist_list.append([\n",
    "            0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "            0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "            0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "            0.004, 0.004, 0.006, 0.002, 0.002, 0.04, 0.002, 0.002, 0.004, 0.04, 0.002, 0.001,\n",
    "            0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "            0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "            0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "            0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "            0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "            0.004, 0.006, 0.006, 0.001, 0.04, 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "            0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "            0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "            0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "            0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "            0.04, 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02,\n",
    "            0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "            0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "        ])\n",
    "    if current_time < 20:\n",
    "        if current_time == 0:\n",
    "            if len(hist_list) == 1:\n",
    "                hist_list.append(queue.Queue())\n",
    "            else:\n",
    "                hist_list[1].queue.clear()\n",
    "        hist_list[1].put(current_wap)\n",
    "        ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[1].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[1].get()\n",
    "        ret = (current_wap - past_wap) / past_wap\n",
    "    # for robustness, if the stock_id is larger than 200, we use the average weight\n",
    "    weight = [hist_list[0][int(stock_id)] if stock_id <= 200 else np.mean(hist_list[0]) for stock_id in\n",
    "              current_data[:, col2index_map['stock_id']]]\n",
    "    synthetic_index = np.sum(np.array(weight, dtype=float) * ret)\n",
    "    res = ret - synthetic_index\n",
    "    # if result is nan, we assign res=0\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return -res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "outputs": [],
   "source": [
    "def stock_40s_ret_deviate_from_index_rank_hedged_opt(current_data: dict, hist_list=[]):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if len(hist_list) == 0:\n",
    "        hist_list.append([\n",
    "            0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "            0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "            0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "            0.004, 0.004, 0.006, 0.002, 0.002, 0.04, 0.002, 0.002, 0.004, 0.04, 0.002, 0.001,\n",
    "            0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "            0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "            0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "            0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "            0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "            0.004, 0.006, 0.006, 0.001, 0.04, 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "            0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "            0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "            0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "            0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "            0.04, 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02,\n",
    "            0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "            0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "        ])\n",
    "    if current_time == 0:\n",
    "        if len(hist_list) == 1:\n",
    "            # then we are at the very start, initialize the hist_list with two queues, one for 40s ret one for 20s ret\n",
    "            hist_list.append(queue.Queue())  # for the 40s ret\n",
    "            hist_list.append(queue.Queue())  # for the 20s ret\n",
    "        else:\n",
    "            # its a new day, we clear the queue\n",
    "            hist_list[1].queue.clear()\n",
    "            hist_list[2].queue.clear()\n",
    "    if current_time < 20:\n",
    "        hist_list[2].put(current_wap)\n",
    "        hedge_20s_ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[2].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[2].get()\n",
    "        hedge_20s_ret = (current_wap - past_wap) / past_wap\n",
    "    if current_time < 40:\n",
    "        hist_list[1].put(current_wap)\n",
    "        ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[1].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[1].get()\n",
    "        ret = (current_wap - past_wap) / past_wap\n",
    "    # for robustness, if the stock_id is larger than 200, we use the average weight\n",
    "    weight = [hist_list[0][int(stock_id)] if stock_id <= 200 else np.mean(hist_list[0]) for stock_id in\n",
    "              current_data[:, col2index_map['stock_id']]]\n",
    "    synthetic_index = np.sum(np.array(weight, dtype=float) * ret)\n",
    "    res = ret - synthetic_index\n",
    "    hedge_20s_ret = (hedge_20s_ret - np.sum(np.array(weight, dtype=float) * hedge_20s_ret))\n",
    "    # if result is nan, we assign res=0\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    res = stats.rankdata(-res) / len(res)\n",
    "    res = (res - 0.5) * 2\n",
    "    res = utils.ols_res(hedge_20s_ret, res, 0.33)\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "outputs": [],
   "source": [
    "def stock_40s_ret_deviate_from_index_rank(current_data: dict, hist_list=[]):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T  # this is faster than pd.DataFrame(current_data).values\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if len(hist_list) == 0:\n",
    "        hist_list.append([\n",
    "            0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "            0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "            0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "            0.004, 0.004, 0.006, 0.002, 0.002, 0.04, 0.002, 0.002, 0.004, 0.04, 0.002, 0.001,\n",
    "            0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "            0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "            0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "            0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "            0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "            0.004, 0.006, 0.006, 0.001, 0.04, 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "            0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "            0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "            0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "            0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "            0.04, 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02,\n",
    "            0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "            0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "        ])\n",
    "    if current_time < 40:\n",
    "        if current_time == 0:\n",
    "            if len(hist_list) == 1:\n",
    "                hist_list.append(queue.Queue())\n",
    "            else:\n",
    "                hist_list[1].queue.clear()\n",
    "        hist_list[1].put(current_wap)\n",
    "        ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[1].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[1].get()\n",
    "        ret = (current_wap - past_wap) / past_wap\n",
    "    # for robustness, if the stock_id is larger than 200, we use the average weight\n",
    "    weight = [hist_list[0][int(stock_id)] if stock_id <= 200 else np.mean(hist_list[0]) for stock_id in\n",
    "              current_data[:, col2index_map['stock_id']]]\n",
    "    synthetic_index = np.sum(np.array(weight, dtype=float) * ret)\n",
    "    res = ret - synthetic_index\n",
    "    # if result is nan, we assign res=0\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return stats.rankdata(-res) / len(res)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "new_factor_list = ['s1_imbalance_signed_pow_opt',\n",
    "                   \"past_10s_ret\",\n",
    "                   \"past_30s_ret_rank\",\n",
    "                   \"stock_20s_ret_deviate_from_index\",\n",
    "                   \"stock_40s_ret_deviate_from_index_rank_hedged_opt\",\n",
    "                   \"stock_40s_ret_deviate_from_index_rank\", ]  # fine toned factor set"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:39:54.952158200Z",
     "start_time": "2023-11-12T09:39:54.865471400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Factor value calculation in train set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor s1_imbalance_signed_pow_opt\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 0 dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\827042783.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor s1_imbalance_signed_pow_opt for 100 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 200 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 300 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 400 dates\n",
      "Accepted!!: Used 17.33 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1/6 [00:17<01:29, 17.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor past_10s_ret\n",
      "Finished calculating factor past_10s_ret for 0 dates\n",
      "Finished calculating factor past_10s_ret for 100 dates\n",
      "Finished calculating factor past_10s_ret for 200 dates\n",
      "Finished calculating factor past_10s_ret for 300 dates\n",
      "Finished calculating factor past_10s_ret for 400 dates\n",
      "Accepted!!: Used 3.98 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:22<00:40, 10.13s/it]C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\1399039670.py:20: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  return -stats.rankdata(res, method='min') / (len(res) + 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor past_30s_ret_rank\n",
      "Finished calculating factor past_30s_ret_rank for 0 dates\n",
      "Finished calculating factor past_30s_ret_rank for 100 dates\n",
      "Finished calculating factor past_30s_ret_rank for 200 dates\n",
      "Finished calculating factor past_30s_ret_rank for 300 dates\n",
      "Finished calculating factor past_30s_ret_rank for 400 dates\n",
      "Accepted!!: Used 6.30 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [00:29<00:25,  8.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor stock_20s_ret_deviate_from_index\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 0 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 100 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 200 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 300 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 400 dates\n",
      "Accepted!!: Used 4.87 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:34<00:14,  7.35s/it]C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\2324114839.py:59: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  res = stats.rankdata(-res) / len(res)\n",
      "D:\\Road2KaggleLord\\Optiver_MOC\\Optiver_MOC_Factor_Research_Framework_Distributed\\in_house_validation\\utils.py:33: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  beta = np.dot(x,y)/np.dot(x,x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 0 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 100 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 200 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 300 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 400 dates\n",
      "Accepted!!: Used 7.96 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [00:43<00:07,  7.76s/it]C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\2636615255.py:46: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  return stats.rankdata(-res) / len(res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 401\n",
      "Start calculating factor stock_40s_ret_deviate_from_index_rank\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 0 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 100 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 200 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 300 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 400 dates\n",
      "Accepted!!: Used 7.17 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:51<00:00,  8.51s/it]\n"
     ]
    }
   ],
   "source": [
    "new_factors_train = {factor_name: utils.flatten_factor_value(\n",
    "    factor_design.run_factor_value(df_train_dic_sorted, eval(factor_name), factor_name), factor_name)[factor_name] for\n",
    "                     factor_name in tqdm(new_factor_list)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:40:46.106121900Z",
     "start_time": "2023-11-12T09:39:54.957158700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Factor value calculation in test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor s1_imbalance_signed_pow_opt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\827042783.py:18: RuntimeWarning: invalid value encountered in divide\n",
      "  res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n",
      " 17%|█▋        | 1/6 [00:03<00:15,  3.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor s1_imbalance_signed_pow_opt for 480 dates\n",
      "Accepted!!: Used 2.92 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor past_10s_ret\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [00:03<00:07,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor past_10s_ret for 480 dates\n",
      "Accepted!!: Used 0.74 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor past_30s_ret_rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\1399039670.py:20: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  return -stats.rankdata(res, method='min') / (len(res) + 1)\n",
      " 50%|█████     | 3/6 [00:05<00:04,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor past_30s_ret_rank for 480 dates\n",
      "Accepted!!: Used 1.27 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor stock_20s_ret_deviate_from_index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [00:06<00:02,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor stock_20s_ret_deviate_from_index for 480 dates\n",
      "Accepted!!: Used 0.96 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\2324114839.py:59: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  res = stats.rankdata(-res) / len(res)\n",
      " 83%|████████▎ | 5/6 [00:08<00:01,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 480 dates\n",
      "Accepted!!: Used 1.61 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor stock_40s_ret_deviate_from_index_rank\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_9632\\2636615255.py:46: DeprecationWarning: Please use `rankdata` from the `scipy.stats` namespace, the `scipy.stats.stats` namespace is deprecated.\n",
      "  return stats.rankdata(-res) / len(res)\n",
      "100%|██████████| 6/6 [00:09<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank for 480 dates\n",
      "Accepted!!: Used 1.49 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_factors_test = {factor_name: utils.flatten_factor_value(\n",
    "    factor_design.run_factor_value(df_test_dic_sorted, eval(factor_name), factor_name), factor_name)[factor_name] for\n",
    "                    factor_name in tqdm(new_factor_list)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:40:55.823356500Z",
     "start_time": "2023-11-12T09:40:46.110122200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factor Backtesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-12T09:40:55.909817900Z",
     "start_time": "2023-11-12T09:40:55.815297600Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_backtest = factor_backtest.Factor_Backtest(existed_factors=existed_factor_train, testing_factors=new_factors_train,\n",
    "                                                factor_performance=factor_performance_train)  # just a formality "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['origin_seconds_in_bucket', 'origin_imbalance_size', 'origin_imbalance_buy_sell_flag', 'origin_reference_price', 'origin_matched_size', 'origin_far_price', 'origin_near_price', 'origin_bid_price', 'origin_bid_size', 'origin_ask_price', 'origin_ask_size', 'origin_wap', 's1_imbalance_signed_pow_opt'])\n"
     ]
    }
   ],
   "source": [
    "print(existed_factor_train.keys())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:40:56.007049700Z",
     "start_time": "2023-11-12T09:40:55.899824800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor s1_imbalance_signed_pow_opt PASSED in-sample performance check with correlation coefficient 0.11812815373942646\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor s1_imbalance_signed_pow_opt FAILED in-sample correlation check with factor s1_imbalance_signed_pow_opt, \n",
      "The pair have correlation 0.9999999999999998\n",
      "This falls in type 2 threshold, >0.7\n",
      "\n",
      "The required performance is 1.2 times the old factor performance 0.11812815373942646 = 0.14175378448731174.\n",
      "Performance of the new factor now is  0.11812815373942646\n",
      "Factor s1_imbalance_signed_pow_opt failed in-sample tests\n",
      "==============================================================================================================\n",
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor past_10s_ret PASSED in-sample performance check with correlation coefficient 0.06664332162654614\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor past_10s_ret passed in-sample pairwise correlation check with all existed factors\n",
      "______________________________________________________________________________________________\n",
      "Factor past_10s_ret passed In-sample tests\n",
      "Out of sample correlation coefficient for factor past_10s_ret is 0.04119108445354642\n",
      "Factor past_10s_ret failed out-of-sample performance \n",
      " in-sample corr = 0.06664332162654614 \n",
      " out-of-sample corr = 0.04119108445354642\n",
      "threshold is 0.0466503251385823\n",
      "Factor past_10s_ret failed Out-of-sample tests\n",
      "==============================================================================================================\n",
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor past_30s_ret_rank PASSED in-sample performance check with correlation coefficient 0.06302002013895729\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor past_30s_ret_rank passed in-sample pairwise correlation check with all existed factors\n",
      "______________________________________________________________________________________________\n",
      "Factor past_30s_ret_rank passed In-sample tests\n",
      "Out of sample correlation coefficient for factor past_30s_ret_rank is 0.042778190274412334\n",
      "Factor past_30s_ret_rank failed out-of-sample performance \n",
      " in-sample corr = 0.06302002013895729 \n",
      " out-of-sample corr = 0.042778190274412334\n",
      "threshold is 0.044114014097270095\n",
      "Factor past_30s_ret_rank failed Out-of-sample tests\n",
      "==============================================================================================================\n",
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor stock_20s_ret_deviate_from_index PASSED in-sample performance check with correlation coefficient 0.08267993902947415\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor stock_20s_ret_deviate_from_index passed in-sample pairwise correlation check with all existed factors\n",
      "______________________________________________________________________________________________\n",
      "Factor stock_20s_ret_deviate_from_index passed In-sample tests\n",
      "Out of sample correlation coefficient for factor stock_20s_ret_deviate_from_index is 0.054359352767095796\n",
      "Factor stock_20s_ret_deviate_from_index passed out-of-sample performance \n",
      " in-sample corr = 0.08267993902947415 \n",
      " out-of-sample corr = 0.054359352767095796\n",
      "Factor stock_20s_ret_deviate_from_index passed Out-of-sample tests\n",
      "Factor stock_20s_ret_deviate_from_index passed all the tests, add to the factor pool\n",
      "No temporary files found, creating one\n",
      "==============================================================================================================\n",
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt PASSED in-sample performance check with correlation coefficient 0.05405080675974954\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt passed in-sample pairwise correlation check with all existed factors\n",
      "______________________________________________________________________________________________\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt passed In-sample tests\n",
      "Out of sample correlation coefficient for factor stock_40s_ret_deviate_from_index_rank_hedged_opt is 0.03917491061016383\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt passed out-of-sample performance \n",
      " in-sample corr = 0.05405080675974954 \n",
      " out-of-sample corr = 0.03917491061016383\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt passed Out-of-sample tests\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt passed all the tests, add to the factor pool\n",
      "Temporary files found, appending to the existed one\n",
      "==============================================================================================================\n",
      "\n",
      "_______________________________________Factor Performance_______________________________________________________\n",
      "Factor stock_40s_ret_deviate_from_index_rank PASSED in-sample performance check with correlation coefficient 0.06356041069195277\n",
      "\n",
      "___________________________________Factor pairwise Correlation__________________________________________________\n",
      "Factor stock_40s_ret_deviate_from_index_rank FAILED in-sample correlation check with factor stock_40s_ret_deviate_from_index_rank_hedged_opt, \n",
      "The pair have correlation 0.9847169595487341\n",
      "This falls in type 2 threshold, >0.7\n",
      "\n",
      "The required performance is 1.2 times the old factor performance 0.05405080675974954 = 0.06486096811169945.\n",
      "Performance of the new factor now is  0.06356041069195277\n",
      "Factor stock_40s_ret_deviate_from_index_rank failed in-sample tests\n",
      "==============================================================================================================\n",
      "\n",
      "\n",
      "______________________________________Overall Conclusion________________________________________________________\n",
      "passed factors:  ['stock_20s_ret_deviate_from_index', 'stock_40s_ret_deviate_from_index_rank_hedged_opt']\n",
      "failed outsample factors:  ['past_10s_ret', 'past_30s_ret_rank']\n",
      "failed insample factors:  ['s1_imbalance_signed_pow_opt', 'stock_40s_ret_deviate_from_index_rank']\n"
     ]
    }
   ],
   "source": [
    "demo_backtest.validate_new_factors(new_factors_train, new_factors_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:41:54.415345500Z",
     "start_time": "2023-11-12T09:40:55.969040100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['origin_seconds_in_bucket', 'origin_imbalance_size', 'origin_imbalance_buy_sell_flag', 'origin_reference_price', 'origin_matched_size', 'origin_far_price', 'origin_near_price', 'origin_bid_price', 'origin_bid_size', 'origin_ask_price', 'origin_ask_size', 'origin_wap'])"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existed_factor_test.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:41:54.617875100Z",
     "start_time": "2023-11-12T09:41:54.426958700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "array([-0.00000000e+00, -0.00000000e+00, -0.00000000e+00, ...,\n        5.85119705e-05,  1.20540846e-04,  1.48540061e-04])"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existed_factor_train['stock_20s_ret_deviate_from_index']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:41:54.768316800Z",
     "start_time": "2023-11-12T09:41:54.608870800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching files: []\n",
      "No temporary files found, no new factors added, returning existed_factors\n"
     ]
    }
   ],
   "source": [
    "existed_factor_test = utils.add_factor_to_existed_test()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:51:40.328885100Z",
     "start_time": "2023-11-12T09:51:35.794153600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['origin_seconds_in_bucket', 'origin_imbalance_size', 'origin_imbalance_buy_sell_flag', 'origin_reference_price', 'origin_matched_size', 'origin_far_price', 'origin_near_price', 'origin_bid_price', 'origin_bid_size', 'origin_ask_price', 'origin_ask_size', 'origin_wap', 's1_imbalance_signed_pow_opt', 'stock_20s_ret_deviate_from_index', 'stock_40s_ret_deviate_from_index_rank_hedged_opt'])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existed_factor_test.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:51:48.080766Z",
     "start_time": "2023-11-12T09:51:48.003363600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching files: ['./in_house_validation\\\\tmp20231112.json', './in_house_validation\\\\tmp2023118.json']\n",
      "Factor stock_20s_ret_deviate_from_index is a new factor, adding the value\n",
      "Factor stock_40s_ret_deviate_from_index_rank_hedged_opt is a new factor, adding the value\n",
      "./in_house_validation\\tmp20231112.json added to existed_factors\n",
      "Factor s1_imbalance_signed_pow_opt already exists in existed_factors, overwriting the value\n",
      "./in_house_validation\\tmp2023118.json added to existed_factors\n",
      "storing the updated existed_factors\n",
      "existed_factors updated, all temporary files deleted\n"
     ]
    }
   ],
   "source": [
    "existed_factor_train = utils.add_factor_to_existed_train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:56:11.005536200Z",
     "start_time": "2023-11-12T09:54:26.230412700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['origin_seconds_in_bucket', 'origin_imbalance_size', 'origin_imbalance_buy_sell_flag', 'origin_reference_price', 'origin_matched_size', 'origin_far_price', 'origin_near_price', 'origin_bid_price', 'origin_bid_size', 'origin_ask_price', 'origin_ask_size', 'origin_wap', 's1_imbalance_signed_pow_opt', 'stock_20s_ret_deviate_from_index', 'stock_40s_ret_deviate_from_index_rank_hedged_opt'])"
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "existed_factor_train.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-12T09:56:11.229567700Z",
     "start_time": "2023-11-12T09:56:11.029595Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

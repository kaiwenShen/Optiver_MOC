{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import queue\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:19:08.082068600Z",
     "start_time": "2023-12-18T22:19:06.384808600Z"
    }
   },
   "id": "dc562065ba97399"
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:19:08.481341400Z",
     "start_time": "2023-12-18T22:19:08.042632600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "outputs": [],
   "source": [
    "from factor_design_distributed_ver1 import utils, factor_design, factor_backtest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:19:08.538013Z",
     "start_time": "2023-12-18T22:19:08.182126900Z"
    }
   },
   "id": "51016c4eff6b3113"
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "outputs": [],
   "source": [
    "# play around the data \n",
    "df_train = pd.read_csv('./research_train_set.csv')\n",
    "\n",
    "# We built a index map to speed up the factor design, you don't need to worry about this.\n",
    "col2index_map = utils.load_json('./factor_design_distributed_ver1/col2index_map.json')\n",
    "# df_train in a dictionary format\n",
    "df_train_dic_sorted = utils.load_json('./factor_design_distributed_ver1/df_train_dic_sorted.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:20:27.244135500Z",
     "start_time": "2023-12-18T22:19:08.537014Z"
    }
   },
   "id": "901d7e519c79d990"
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matching files: []\n",
      "No temporary files found, no new factors added, returning existed_factors\n"
     ]
    }
   ],
   "source": [
    "existed_factors = utils.add_factor_to_existed()  # this function will add all temp files to the existed factor, then return the existed factor. usually take 1 min"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:43.037515100Z",
     "start_time": "2023-12-18T22:20:27.250139900Z"
    }
   },
   "id": "6fd90c1f64969260"
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [],
   "source": [
    "factor_df = pd.DataFrame(existed_factors)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:43.416819300Z",
     "start_time": "2023-12-18T22:21:43.009517700Z"
    }
   },
   "id": "ba5a8890fc247bd8"
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": "origin_seconds_in_bucket                               0\norigin_imbalance_size                                  0\norigin_imbalance_buy_sell_flag                         0\norigin_reference_price                                 0\norigin_matched_size                                    0\norigin_far_price                                       0\norigin_near_price                                      0\norigin_bid_price                                       0\norigin_bid_size                                        0\norigin_ask_price                                       0\norigin_ask_size                                        0\norigin_wap                                             0\ns1_imbalance_signed_pow_opt                            0\nstock_20s_ret_deviate_from_index                       0\nstock_40s_ret_deviate_from_index_rank_hedged_opt       0\ntriplet_imbalance_bid_ask_wap_signed_pow_opt_hedged    0\nprice_pressure                                         0\ndtype: int64"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if any na in the factor_df\n",
    "factor_df.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:43.761272800Z",
     "start_time": "2023-12-18T22:21:43.425822Z"
    }
   },
   "id": "8004a837e295f95"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# reconstruct original data factor using ffill method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e136271f5a026e2"
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./research_train_set.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:56.599056800Z",
     "start_time": "2023-12-18T22:21:43.764280900Z"
    }
   },
   "id": "e66d2ba682c0b9e"
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "outputs": [
    {
     "data": {
      "text/plain": "stock_id                         0\ndate_id                          0\nseconds_in_bucket                0\nimbalance_size                 165\nimbalance_buy_sell_flag          0\nreference_price                165\nmatched_size                   165\nfar_price                  2408871\nnear_price                 2377155\nbid_price                      165\nbid_size                         0\nask_price                      165\nask_size                         0\nwap                            165\ntarget                          87\ntime_id                          0\nrow_id                           0\ndtype: int64"
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isna().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:57.873540200Z",
     "start_time": "2023-12-18T22:21:56.603057400Z"
    }
   },
   "id": "cdb6eafc51031b33"
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "outputs": [],
   "source": [
    "def ffill_current_data(current_data: dict, hist_list: list):\n",
    "    current_data = np.array(list(current_data.values()),\n",
    "                            dtype=float).T\n",
    "    if len(hist_list) == 0:\n",
    "        # print(\"initialize\")\n",
    "        old_data = np.full((300, current_data.shape[1]), np.nan, dtype=float)\n",
    "        old_data[:, 0] = np.arange(0, 300)\n",
    "        rows_to_update = np.isin(old_data[:, 0], current_data[:, 0])\n",
    "        old_data[rows_to_update, 1:] = current_data[np.searchsorted(current_data[:, 0], old_data[rows_to_update, 0]),\n",
    "                                       1:]\n",
    "        hist_list.append(old_data)  # initializing the hist_list\n",
    "        return current_data\n",
    "    else:\n",
    "        old_data = hist_list[0]\n",
    "        # first fill nan with old data\n",
    "        coordinate_to_replace = np.argwhere(np.isnan(current_data))\n",
    "        current_data[coordinate_to_replace[:, 0], coordinate_to_replace[:, 1]] = old_data[\n",
    "            coordinate_to_replace[:, 0], coordinate_to_replace[:, 1]]\n",
    "        # then update old data with current data\n",
    "        rows_to_update = np.isin(old_data[:, 0], current_data[:, 0])\n",
    "        old_data[rows_to_update, 1:] = current_data[np.searchsorted(current_data[:, 0], old_data[rows_to_update, 0]),\n",
    "                                       1:]\n",
    "        hist_list[0] = old_data\n",
    "        return current_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.059899600Z",
     "start_time": "2023-12-18T22:21:57.888539400Z"
    }
   },
   "id": "be3df370c44e587"
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "def ffill_factor_res(factor_res: np.ndarray,stock_id: np.ndarray, hist_list: list, used_hist_list: int):\n",
    "    current_res = np.hstack((stock_id.reshape(-1,1),factor_res.reshape(-1,1)))\n",
    "    if len(hist_list) == used_hist_list:\n",
    "        old_data = np.full((300, 2), np.nan, dtype=float)\n",
    "        old_data[:, 0] = np.arange(0, 300)\n",
    "        rows_to_update = np.isin(old_data[:, 0], current_res[:, 0])\n",
    "        old_data[rows_to_update, 1:] = current_res[np.searchsorted(current_res[:, 0], old_data[rows_to_update, 0]),\n",
    "                                       1:]\n",
    "        hist_list.append(old_data)  # initializing the hist_list\n",
    "        return current_res[:,1]\n",
    "    else:\n",
    "        old_data = hist_list[used_hist_list]\n",
    "        # first fill nan with old data\n",
    "        coordinate_to_replace = np.argwhere(np.isnan(current_res[:,1]))\n",
    "        current_res[coordinate_to_replace[:, 0], 1] = old_data[\n",
    "            coordinate_to_replace[:, 0], 1]\n",
    "        # then update old data with current data\n",
    "        rows_to_update = np.isin(old_data[:, 0], current_res[:, 0])\n",
    "\n",
    "        old_data[rows_to_update, 1:] = current_res[np.searchsorted(current_res[:, 0], old_data[rows_to_update, 0]),\n",
    "                                       1:]\n",
    "        hist_list[used_hist_list] = old_data\n",
    "        return current_res[:,1]\n",
    "        \n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.199414100Z",
     "start_time": "2023-12-18T22:21:58.028899600Z"
    }
   },
   "id": "96d68668d4423495"
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [
    "def origin_seconds_in_bucket(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    # get ffilled data\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['seconds_in_bucket']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.371947200Z",
     "start_time": "2023-12-18T22:21:58.160409800Z"
    }
   },
   "id": "68fa524b65c38840"
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "def origin_imbalance_size(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    # get ffilled data\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['imbalance_size']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.524885300Z",
     "start_time": "2023-12-18T22:21:58.286949400Z"
    }
   },
   "id": "723df354b98811f3"
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "def origin_imbalance_buy_sell_flag(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['imbalance_buy_sell_flag']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.617530900Z",
     "start_time": "2023-12-18T22:21:58.408876300Z"
    }
   },
   "id": "8595823ecdc03e37"
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "def origin_reference_price(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    \n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['reference_price']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.785342600Z",
     "start_time": "2023-12-18T22:21:58.538531300Z"
    }
   },
   "id": "f4994fa4f4735e09"
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [],
   "source": [
    "def origin_matched_size(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['matched_size']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.850199400Z",
     "start_time": "2023-12-18T22:21:58.665915700Z"
    }
   },
   "id": "8ffd82ba6187e1da"
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [],
   "source": [
    "def origin_far_price(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['far_price']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:58.967133400Z",
     "start_time": "2023-12-18T22:21:58.798553700Z"
    }
   },
   "id": "5fabf4d69c35d3da"
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "outputs": [],
   "source": [
    "def origin_near_price(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['near_price']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.163715400Z",
     "start_time": "2023-12-18T22:21:58.939132600Z"
    }
   },
   "id": "58b0b97b50a56171"
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "outputs": [],
   "source": [
    "def origin_bid_price(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['bid_price']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.378140800Z",
     "start_time": "2023-12-18T22:21:59.066158400Z"
    }
   },
   "id": "c7a9a8a827f62262"
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "outputs": [],
   "source": [
    "def origin_bid_size(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['bid_size']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.468621300Z",
     "start_time": "2023-12-18T22:21:59.228036100Z"
    }
   },
   "id": "a38622ee2fad73e6"
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "outputs": [],
   "source": [
    "def origin_ask_price(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    \n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['ask_price']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    # res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.653205300Z",
     "start_time": "2023-12-18T22:21:59.384146400Z"
    }
   },
   "id": "eaafcc9893e7968b"
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "outputs": [],
   "source": [
    "def origin_ask_size(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    \n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['ask_size']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    # res[np.isnan(res)] = 0\n",
    "    return res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.853576600Z",
     "start_time": "2023-12-18T22:21:59.536527200Z"
    }
   },
   "id": "304915185ba03ec0"
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "outputs": [],
   "source": [
    "def origin_wap(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    \"\"\"same logic as s1_imbalance, but only use matched volume\"\"\"\n",
    "    \n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = current_data[:, col2index_map['wap']]\n",
    "    # after firstfill, if there is still nan (which can happen if the data start with nan), then fill with 0\n",
    "    # res[np.isnan(res)] = 0\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:21:59.891568700Z",
     "start_time": "2023-12-18T22:21:59.691766500Z"
    }
   },
   "id": "b7095f6305574560"
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "outputs": [],
   "source": [
    "def s1_imbalance_signed_pow_opt(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    '''\n",
    "    This will be the main function to design your factors for the competition. Please\n",
    "    define only one factor here each time. We provide you with:\n",
    "\n",
    "    Current_data: a dictionary in the format of {column_name: column_value}, where column_name is from the original\n",
    "    dataframe\n",
    "\n",
    "    hist_list: A list for you to save the previous factor values (optional). For instance,\n",
    "    if you are calculating a 100-day Moving Average (MA), then you can save the first calculated\n",
    "    MA in hist_list, and then for the next MA calculation, you can use the saved ones.\n",
    "    '''\n",
    "    ###################### ADD YOUR CODE HERE FOR FACTORS DESIGN ######################\n",
    "    # convert the current_data to your choice of numpy or pandas dataframe\n",
    "    # current_data = pd.DataFrame(current_data)\n",
    "    current_data =ffill_current_data(current_data,hist_list)\n",
    "    res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n",
    "          (current_data[:, col2index_map['bid_size']] + current_data[:, col2index_map['ask_size']])\n",
    "    res = np.sign(-res) * np.abs(\n",
    "        res) ** 1.4242424242424243  \n",
    "    res = ffill_factor_res(res,current_data[:, col2index_map['stock_id']],hist_list,1)\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return res\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:22:00.018834700Z",
     "start_time": "2023-12-18T22:21:59.830931600Z"
    }
   },
   "id": "ef0b49ffbbef3cad"
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "outputs": [],
   "source": [
    "def stock_20s_ret_deviate_from_index(current_data: dict, hist_list=[]):\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if len(hist_list) == 1:\n",
    "        hist_list.append([\n",
    "            0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "            0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "            0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "            0.004, 0.004, 0.006, 0.002, 0.002, 0.04, 0.002, 0.002, 0.004, 0.04, 0.002, 0.001,\n",
    "            0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "            0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "            0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "            0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "            0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "            0.004, 0.006, 0.006, 0.001, 0.04, 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "            0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "            0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "            0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "            0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "            0.04, 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02,\n",
    "            0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "            0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "        ])\n",
    "    if current_time < 20:\n",
    "        if current_time == 0:\n",
    "            if len(hist_list) == 2:\n",
    "                hist_list.append(queue.Queue())\n",
    "            else:\n",
    "                hist_list[2].queue.clear()\n",
    "        hist_list[2].put(current_wap)\n",
    "        ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[2].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[2].get()\n",
    "        ret = (current_wap - past_wap) / past_wap\n",
    "    # for robustness, if the stock_id is larger than 200, we use the average weight\n",
    "    weight = [hist_list[1][int(stock_id)] if stock_id <= 200 else np.mean(hist_list[1]) for stock_id in\n",
    "              current_data[:, col2index_map['stock_id']]]\n",
    "    synthetic_index = np.sum(np.array(weight, dtype=float) * ret)\n",
    "    res = ret - synthetic_index\n",
    "    res = ffill_factor_res(res,current_data[:, col2index_map['stock_id']],hist_list,3)\n",
    "    # if result is nan, we assign res=0\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    return -res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:22:00.182167600Z",
     "start_time": "2023-12-18T22:21:59.947833300Z"
    }
   },
   "id": "a4c8c3598943d166"
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "outputs": [],
   "source": [
    "def stock_40s_ret_deviate_from_index_rank_hedged_opt(current_data: dict, hist_list=[]):\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    current_time = current_data[0, col2index_map['seconds_in_bucket']]\n",
    "    current_wap = current_data[:, col2index_map['wap']]\n",
    "    if len(hist_list) == 1:\n",
    "        hist_list.append([\n",
    "            0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "            0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "            0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "            0.004, 0.004, 0.006, 0.002, 0.002, 0.04, 0.002, 0.002, 0.004, 0.04, 0.002, 0.001,\n",
    "            0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "            0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "            0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "            0.02, 0.004, 0.006, 0.002, 0.02, 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "            0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "            0.004, 0.006, 0.006, 0.001, 0.04, 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "            0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "            0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "            0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "            0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "            0.04, 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02, 0.004, 0.002, 0.006, 0.02,\n",
    "            0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "            0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "        ])\n",
    "    if current_time == 0:\n",
    "        if len(hist_list) == 2:\n",
    "            # then we are at the very start, initialize the hist_list with two queues, one for 40s ret one for 20s ret\n",
    "            hist_list.append(queue.Queue())  # for the 40s ret\n",
    "            hist_list.append(queue.Queue())  # for the 20s ret\n",
    "        else:\n",
    "            # its a new day, we clear the queue\n",
    "            hist_list[2].queue.clear()\n",
    "            hist_list[3].queue.clear()\n",
    "    if current_time < 20:\n",
    "        hist_list[3].put(current_wap)\n",
    "        hedge_20s_ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[3].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[3].get()\n",
    "        hedge_20s_ret = (current_wap - past_wap) / past_wap\n",
    "    if current_time < 40:\n",
    "        hist_list[2].put(current_wap)\n",
    "        ret = np.zeros(current_wap.shape)\n",
    "    else:\n",
    "        hist_list[2].put(current_wap)\n",
    "        # calculate the past 60s return\n",
    "        past_wap = hist_list[2].get()\n",
    "        ret = (current_wap - past_wap) / past_wap\n",
    "    # for robustness, if the stock_id is larger than 200, we use the average weight\n",
    "    weight = [hist_list[1][int(stock_id)] if stock_id <= 200 else np.mean(hist_list[1]) for stock_id in\n",
    "              current_data[:, col2index_map['stock_id']]]\n",
    "    synthetic_index = np.sum(np.array(weight, dtype=float) * ret)\n",
    "    res = ret - synthetic_index\n",
    "    hedge_20s_ret = (hedge_20s_ret - np.sum(np.array(weight, dtype=float) * hedge_20s_ret))\n",
    "    # if result is nan, we assign res=0\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "    res = stats.rankdata(-res) / len(res)\n",
    "    res = (res - 0.5) * 2\n",
    "    res = utils.ols_res(hedge_20s_ret, res, 0.33)\n",
    "    res = ffill_factor_res(res,current_data[:, col2index_map['stock_id']],hist_list,4)\n",
    "    res[np.isnan(res)] = 0  # this is the easiest way to fill nan\n",
    "\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:22:00.346556400Z",
     "start_time": "2023-12-18T22:22:00.135556Z"
    }
   },
   "id": "9190e18ef50b0c6f"
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "outputs": [],
   "source": [
    "def triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged(current_data: dict,hist_list=[])->np.ndarray:\n",
    "    def triplet_imbalance_cal(data,col):\n",
    "        assert len(col)==3\n",
    "        temp= np.vstack([data[:,col2index_map[col[0]]],data[:,col2index_map[col[1]]],data[:,col2index_map[col[2]]]])\n",
    "        max_val = np.max(temp,axis=0)\n",
    "        min_val = np.min(temp,axis=0)\n",
    "        mid_val = np.sum(temp,axis=0)-max_val-min_val\n",
    "        \n",
    "        # print(max_val.shape)\n",
    "        return (max_val-mid_val)/(max_val+mid_val+min_val)\n",
    "    current_data = ffill_current_data(current_data,hist_list)\n",
    "    res = triplet_imbalance_cal(current_data,['bid_price','ask_price','wap'])\n",
    "    res = np.sign(res)*np.abs(res)**0.65\n",
    "    # s1_imbalance = np.sign(current_data[:, col2index_map['ask_size']] - current_data[:, col2index_map['bid_size']])\n",
    "    # s1_imbalance[np.isnan(s1_imbalance)] = 0  # this is the fastest w to fill nan\n",
    "    # res = utils.ols_res(s1_imbalance,res,0.5) # The return value MUSE BE a numpy array, with no NaN value\n",
    "    res = ffill_factor_res(res,current_data[:, col2index_map['stock_id']],hist_list,1)\n",
    "    res[np.isnan(res)] = 0  # this is the fastest way to fill nan\n",
    "    return res"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:22:00.466840600Z",
     "start_time": "2023-12-18T22:22:00.308900900Z"
    }
   },
   "id": "1c474114780f545e"
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "outputs": [],
   "source": [
    "def price_pressure(current_data: dict, hist_list=[]) -> np.ndarray:\n",
    "    '''\n",
    "    This will be the main function to design your factors for the competition. Please\n",
    "    define only one factor here each time. We provide you with:\n",
    "\n",
    "    Current_data: a dictionary in the format of {column_name: column_value}, where column_name is from the original\n",
    "    dataframe\n",
    "\n",
    "    hist_list: A list for you to save the previous factor values (optional). For instance,\n",
    "    if you are calculating a 100-day Moving Average (MA), then you can save the first calculated\n",
    "    MA in hist_list, and then for the next MA calculation, you can use the saved ones.\n",
    "    '''\n",
    "    ###################### ADD YOUR CODE HERE FOR FACTORS DESIGN ######################\n",
    "    # convert the current_data to your choice of numpy or pandas dataframe\n",
    "    # current_data = pd.DataFrame(current_data)\n",
    "    current_data = ffill_current_data(current_data, hist_list)\n",
    "    res = ((current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n",
    "          (current_data[:, col2index_map['bid_size']] + current_data[:, col2index_map['ask_size']])) * \\\n",
    "          (current_data[:, col2index_map['ask_price']] - current_data[:, col2index_map['bid_price']])\n",
    "    ############################## NAN/Inf handling ######################################\n",
    "    # if you have nan in your factor value, please fill it reasonably\n",
    "    # res = np.nan_to_num(res) # this is slow because it also checks for inf.\n",
    "    # res = np.where(np.isnan(res), 0, res)  # this is slightly faster than np.nan_to_num\n",
    "    res = ffill_factor_res(res,current_data[:, col2index_map['stock_id']],hist_list,1)\n",
    "    res[np.isnan(res)] = 0  # this is the fastest way to fill nan\n",
    "    ############################## END OF YOUR CODE ##############################\n",
    "    return -res  # The return value MUSE BE a numpy array, with no NaN value\n",
    "    ####################################################################################\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:22:00.580013800Z",
     "start_time": "2023-12-18T22:22:00.423844900Z"
    }
   },
   "id": "e3c9d13795efba2d"
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_seconds_in_bucket\n",
      "Finished calculating factor origin_seconds_in_bucket for 0 dates\n",
      "Finished calculating factor origin_seconds_in_bucket for 100 dates\n",
      "Finished calculating factor origin_seconds_in_bucket for 200 dates\n",
      "Finished calculating factor origin_seconds_in_bucket for 300 dates\n",
      "Finished calculating factor origin_seconds_in_bucket for 400 dates\n",
      "Accepted!!: Used 11.21 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 1/17 [00:12<03:12, 12.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_imbalance_size\n",
      "Finished calculating factor origin_imbalance_size for 0 dates\n",
      "Finished calculating factor origin_imbalance_size for 100 dates\n",
      "Finished calculating factor origin_imbalance_size for 200 dates\n",
      "Finished calculating factor origin_imbalance_size for 300 dates\n",
      "Finished calculating factor origin_imbalance_size for 400 dates\n",
      "Accepted!!: Used 11.56 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 2/17 [00:24<03:07, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_imbalance_buy_sell_flag\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 0 dates\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 100 dates\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 200 dates\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 300 dates\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 400 dates\n",
      "Accepted!!: Used 12.02 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 3/17 [00:38<02:59, 12.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_reference_price\n",
      "Finished calculating factor origin_reference_price for 0 dates\n",
      "Finished calculating factor origin_reference_price for 100 dates\n",
      "Finished calculating factor origin_reference_price for 200 dates\n",
      "Finished calculating factor origin_reference_price for 300 dates\n",
      "Finished calculating factor origin_reference_price for 400 dates\n",
      "Accepted!!: Used 10.79 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 4/17 [00:49<02:40, 12.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_matched_size\n",
      "Finished calculating factor origin_matched_size for 0 dates\n",
      "Finished calculating factor origin_matched_size for 100 dates\n",
      "Finished calculating factor origin_matched_size for 200 dates\n",
      "Finished calculating factor origin_matched_size for 300 dates\n",
      "Finished calculating factor origin_matched_size for 400 dates\n",
      "Accepted!!: Used 11.40 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 5/17 [01:02<02:29, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_far_price\n",
      "Finished calculating factor origin_far_price for 0 dates\n",
      "Finished calculating factor origin_far_price for 100 dates\n",
      "Finished calculating factor origin_far_price for 200 dates\n",
      "Finished calculating factor origin_far_price for 300 dates\n",
      "Finished calculating factor origin_far_price for 400 dates\n",
      "Accepted!!: Used 11.41 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 6/17 [01:15<02:17, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_near_price\n",
      "Finished calculating factor origin_near_price for 0 dates\n",
      "Finished calculating factor origin_near_price for 100 dates\n",
      "Finished calculating factor origin_near_price for 200 dates\n",
      "Finished calculating factor origin_near_price for 300 dates\n",
      "Finished calculating factor origin_near_price for 400 dates\n",
      "Accepted!!: Used 14.71 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 7/17 [01:31<02:16, 13.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_bid_price\n",
      "Finished calculating factor origin_bid_price for 0 dates\n",
      "Finished calculating factor origin_bid_price for 100 dates\n",
      "Finished calculating factor origin_bid_price for 200 dates\n",
      "Finished calculating factor origin_bid_price for 300 dates\n",
      "Finished calculating factor origin_bid_price for 400 dates\n",
      "Accepted!!: Used 11.01 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 8/17 [01:42<01:57, 13.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_bid_size\n",
      "Finished calculating factor origin_bid_size for 0 dates\n",
      "Finished calculating factor origin_bid_size for 100 dates\n",
      "Finished calculating factor origin_bid_size for 200 dates\n",
      "Finished calculating factor origin_bid_size for 300 dates\n",
      "Finished calculating factor origin_bid_size for 400 dates\n",
      "Accepted!!: Used 11.19 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 9/17 [01:54<01:41, 12.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_ask_price\n",
      "Finished calculating factor origin_ask_price for 0 dates\n",
      "Finished calculating factor origin_ask_price for 100 dates\n",
      "Finished calculating factor origin_ask_price for 200 dates\n",
      "Finished calculating factor origin_ask_price for 300 dates\n",
      "Finished calculating factor origin_ask_price for 400 dates\n",
      "Accepted!!: Used 11.04 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 10/17 [02:06<01:27, 12.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_ask_size\n",
      "Finished calculating factor origin_ask_size for 0 dates\n",
      "Finished calculating factor origin_ask_size for 100 dates\n",
      "Finished calculating factor origin_ask_size for 200 dates\n",
      "Finished calculating factor origin_ask_size for 300 dates\n",
      "Finished calculating factor origin_ask_size for 400 dates\n",
      "Accepted!!: Used 11.81 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 11/17 [02:20<01:16, 12.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor origin_wap\n",
      "Finished calculating factor origin_wap for 0 dates\n",
      "Finished calculating factor origin_wap for 100 dates\n",
      "Finished calculating factor origin_wap for 200 dates\n",
      "Finished calculating factor origin_wap for 300 dates\n",
      "Finished calculating factor origin_wap for 400 dates\n",
      "Accepted!!: Used 11.01 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 12/17 [02:31<01:02, 12.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor s1_imbalance_signed_pow_opt\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 0 dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_26000\\735742873.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor s1_imbalance_signed_pow_opt for 100 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 200 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 300 dates\n",
      "Finished calculating factor s1_imbalance_signed_pow_opt for 400 dates\n",
      "Accepted!!: Used 16.31 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 13/17 [02:49<00:55, 13.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor stock_20s_ret_deviate_from_index\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 0 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 100 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 200 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 300 dates\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 400 dates\n",
      "Accepted!!: Used 18.57 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 14/17 [03:08<00:46, 15.57s/it]D:\\Road2KaggleLord\\Optiver_MOC\\Optiver_MOC_Factor_Research_Framework_Distributed\\factor_design_distributed_ver1\\utils.py:32: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  beta = np.dot(x,y)/np.dot(x,x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 0 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 100 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 200 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 300 dates\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 400 dates\n",
      "Accepted!!: Used 26.24 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 15/17 [03:35<00:38, 19.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 0 dates\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 100 dates\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 200 dates\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 300 dates\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 400 dates\n",
      "Accepted!!: Used 16.93 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 16/17 [03:53<00:18, 18.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start calculating factor price_pressure\n",
      "Finished calculating factor price_pressure for 0 dates\n",
      "Finished calculating factor price_pressure for 100 dates\n",
      "Finished calculating factor price_pressure for 200 dates\n",
      "Finished calculating factor price_pressure for 300 dates\n",
      "Finished calculating factor price_pressure for 400 dates\n",
      "Accepted!!: Used 15.33 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [04:09<00:00, 14.69s/it]\n"
     ]
    }
   ],
   "source": [
    "new_factor_list = ['origin_'+item for item in df_train.columns[2:-3]]\n",
    "new_factor_list+=['s1_imbalance_signed_pow_opt','stock_20s_ret_deviate_from_index','stock_40s_ret_deviate_from_index_rank_hedged_opt','triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged','price_pressure']\n",
    "#new_factor_list=['stock_40s_ret_deviate_from_index_rank_hedged_opt',]\n",
    "# DO NOT MODIFY THE FOLLOWING CODE\n",
    "# Run this cell once you want to calculate your factor values and prepare for the test of your factor performance!\n",
    "new_factors = {\n",
    "    factor_name: utils.flatten_factor_value(\n",
    "        factor_design.run_factor_value(df_train_dic_sorted, eval(factor_name), factor_name), factor_name)[factor_name]\n",
    "    for factor_name in tqdm(new_factor_list)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:26:10.467099400Z",
     "start_time": "2023-12-18T22:22:00.543355600Z"
    }
   },
   "id": "6052aafa58224956"
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_seconds_in_bucket has correlation to target 0.0031411326809556643\n",
      "origin_imbalance_size has correlation to target 0.00024120719792637867\n",
      "origin_imbalance_buy_sell_flag has correlation to target 0.016656949485659357\n",
      "origin_reference_price has correlation to target 0.01873604844356825\n",
      "origin_matched_size has correlation to target 0.0008940093903293907\n",
      "origin_far_price has correlation to target 0.0014903753836927956\n",
      "origin_near_price has correlation to target 0.005637790885216793\n",
      "origin_bid_price has correlation to target 0.024357965628517917\n",
      "origin_bid_size has correlation to target 0.01802849277176966\n",
      "origin_ask_price has correlation to target 0.022670265167399756\n",
      "origin_ask_size has correlation to target 0.015096386763995221\n",
      "origin_wap has correlation to target 0.03702305889673652\n",
      "s1_imbalance_signed_pow_opt has correlation to target 0.11812660948303615\n",
      "stock_20s_ret_deviate_from_index has correlation to target 0.08297931229149574\n",
      "stock_40s_ret_deviate_from_index_rank_hedged_opt has correlation to target 0.05325576601825008\n",
      "triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged has correlation to target 0.1046910037843893\n",
      "price_pressure has correlation to target 0.15130494585277615\n"
     ]
    }
   ],
   "source": [
    "# check if all values in new_factor do not contain nan, no NA is allowed in the factor value\n",
    "for factor_name, factor_value in new_factors.items():\n",
    "    assert not np.isnan(factor_value).any(), f'{factor_name} contains nan'\n",
    "    assert not np.isinf(factor_value).any(), f'{factor_name} contains inf'\n",
    "    print(f'{factor_name} has correlation to target {np.corrcoef(factor_value, df_train[\"target\"].fillna(0))[0, 1]}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:26:13.331340600Z",
     "start_time": "2023-12-18T22:26:10.456567900Z"
    }
   },
   "id": "cc00dd1fc0a211b2"
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [],
   "source": [
    "utils.dump_json_factors(new_factors, './ffill_factors.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:29:17.512165700Z",
     "start_time": "2023-12-18T22:26:13.305701800Z"
    }
   },
   "id": "2c9e5a31d601f90d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Produce factor data on testing set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8f2ea5cbbd2ffb99"
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [],
   "source": [
    "from in_house_validation import utils, factor_design, factor_backtest"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:35:16.935794600Z",
     "start_time": "2023-12-18T22:35:16.651682100Z"
    }
   },
   "id": "cbd919df40cd3c5b"
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('./research_test_set.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:33:58.826228100Z",
     "start_time": "2023-12-18T22:33:55.374081300Z"
    }
   },
   "id": "b7bf26772d2b69bb"
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "outputs": [],
   "source": [
    "df_test_dic_sorted = utils.load_json('./in_house_validation/test_data_dic_sorted.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:34:40.339489300Z",
     "start_time": "2023-12-18T22:34:28.313743400Z"
    }
   },
   "id": "9b97e2662948f07f"
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/17 [00:00<?, ?it/s]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_seconds_in_bucket\n",
      "Finished calculating factor origin_seconds_in_bucket for 480 dates\n",
      "Accepted!!: Used 5.02 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 1/17 [00:05<01:24,  5.28s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_imbalance_size\n",
      "Finished calculating factor origin_imbalance_size for 480 dates\n",
      "Accepted!!: Used 2.83 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 2/17 [00:08<01:00,  4.02s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_imbalance_buy_sell_flag\n",
      "Finished calculating factor origin_imbalance_buy_sell_flag for 480 dates\n",
      "Accepted!!: Used 2.96 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 3/17 [00:11<00:51,  3.67s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_reference_price\n",
      "Finished calculating factor origin_reference_price for 480 dates\n",
      "Accepted!!: Used 2.90 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▎       | 4/17 [00:14<00:44,  3.46s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_matched_size\n",
      "Finished calculating factor origin_matched_size for 480 dates\n",
      "Accepted!!: Used 2.57 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▉       | 5/17 [00:17<00:38,  3.21s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_far_price\n",
      "Finished calculating factor origin_far_price for 480 dates\n",
      "Accepted!!: Used 2.72 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 35%|███▌      | 6/17 [00:20<00:34,  3.13s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_near_price\n",
      "Finished calculating factor origin_near_price for 480 dates\n",
      "Accepted!!: Used 3.96 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 41%|████      | 7/17 [00:24<00:35,  3.52s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_bid_price\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 47%|████▋     | 8/17 [00:28<00:31,  3.52s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor origin_bid_price for 480 dates\n",
      "Accepted!!: Used 3.31 seconds for calculation factors. The limit is 300 seconds.\n",
      "Number of dates: 80\n",
      "Start calculating factor origin_bid_size\n",
      "Finished calculating factor origin_bid_size for 480 dates\n",
      "Accepted!!: Used 2.40 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 53%|█████▎    | 9/17 [00:30<00:25,  3.23s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_ask_price\n",
      "Finished calculating factor origin_ask_price for 480 dates\n",
      "Accepted!!: Used 2.67 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 59%|█████▉    | 10/17 [00:33<00:21,  3.13s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_ask_size\n",
      "Finished calculating factor origin_ask_size for 480 dates\n",
      "Accepted!!: Used 3.32 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 65%|██████▍   | 11/17 [00:37<00:19,  3.29s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor origin_wap\n",
      "Finished calculating factor origin_wap for 480 dates\n",
      "Accepted!!: Used 4.35 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████   | 12/17 [00:42<00:18,  3.71s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor s1_imbalance_signed_pow_opt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kevin\\AppData\\Local\\Temp\\ipykernel_26000\\735742873.py:17: RuntimeWarning: invalid value encountered in divide\n",
      "  res = (current_data[:, col2index_map['bid_size']] - current_data[:, col2index_map['ask_size']]) / \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor s1_imbalance_signed_pow_opt for 480 dates\n",
      "Accepted!!: Used 5.34 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▋  | 13/17 [00:47<00:17,  4.28s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor stock_20s_ret_deviate_from_index\n",
      "Finished calculating factor stock_20s_ret_deviate_from_index for 480 dates\n",
      "Accepted!!: Used 7.07 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 14/17 [00:55<00:15,  5.19s/it]\u001B[AD:\\Road2KaggleLord\\Optiver_MOC\\Optiver_MOC_Factor_Research_Framework_Distributed\\in_house_validation\\utils.py:33: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  beta = np.dot(x,y)/np.dot(x,x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt\n",
      "Finished calculating factor stock_40s_ret_deviate_from_index_rank_hedged_opt for 480 dates\n",
      "Accepted!!: Used 6.33 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 15/17 [01:01<00:11,  5.60s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged\n",
      "Finished calculating factor triplet_imbalance_bid_ask_wap_signed_pow_opt_hedged for 480 dates\n",
      "Accepted!!: Used 3.88 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 16/17 [01:05<00:05,  5.14s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dates: 80\n",
      "Start calculating factor price_pressure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 17/17 [01:09<00:00,  4.07s/it]\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished calculating factor price_pressure for 480 dates\n",
      "Accepted!!: Used 3.32 seconds for calculation factors. The limit is 300 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_factors_test = {factor_name: utils.flatten_factor_value(\n",
    "    factor_design.run_factor_value(df_test_dic_sorted, eval(factor_name), factor_name), factor_name)[factor_name] for\n",
    "                    factor_name in tqdm(new_factor_list)}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:36:28.102529700Z",
     "start_time": "2023-12-18T22:35:18.663647600Z"
    }
   },
   "id": "7915b33ef1ebce20"
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "utils.dump_json_factors(new_factors_test, './ffill_factors_test.json')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-18T22:37:13.974249600Z",
     "start_time": "2023-12-18T22:36:31.356668400Z"
    }
   },
   "id": "4ef459428e5e02be"
  },
  {
   "cell_type": "markdown",
   "source": [
    "ml"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3acc750062578f6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3e19edd32f2d261d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
